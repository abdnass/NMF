{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "from nltk import word_tokenize, pos_tag, download\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/max/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/max/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/max/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/max/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download relevant nltk datasets\n",
    "\n",
    "download(\"wordnet\")\n",
    "download(\"omw-1.4\")\n",
    "download(\"punkt\")\n",
    "download(\"averaged_perceptron_tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "n_docs = -1 # all documents (takes a while to preprocess!)\n",
    "n_topics = 20 # number of topics to extract (rank)\n",
    "max_iter = 1000 # number of iterations in the NMF\n",
    "n_top_words = 10 # number of words to display for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "data, _ = fetch_20newsgroups(\n",
    "    shuffle=True,\n",
    "    random_state=0,\n",
    "    remove=(\"headers\", \"footers\", \"quotes\"),\n",
    "    return_X_y=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "\n",
    "def preprocess(text: str) -> str:\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    cleaned = [token for token in tokens if token.isalnum()]\n",
    "    nouns = [word for (word, pos) in pos_tag(cleaned) if pos in (\"NN\", \"NNS\", \"NNP\")]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = [lemmatizer.lemmatize(noun, pos=\"n\") for noun in nouns]\n",
    "    return \" \".join(lemmatized)\n",
    "\n",
    "data_pped = map(preprocess, data[:n_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize the documents using term frequency-inverse document frequency\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "doc_vectors = vectorizer.fit_transform(data_pped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use NMF to decompose the document vectors into topic vectors\n",
    "nmf = NMF(n_components=n_topics, init=\"nndsvda\", random_state=0, max_iter=max_iter)\n",
    "topic_vectors = nmf.fit_transform(doc_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: people thing life person armenian world religion point government lot\n",
      "Topic 1: window application manager font server memory screen display client size\n",
      "Topic 2: drive disk scsi controller hd ide tape cable mac jumper\n",
      "Topic 3: team player year league season fan hockey run nhl baseball\n",
      "Topic 4: chip key encryption clipper phone algorithm escrow government number bit\n",
      "Topic 5: card video bus slot memory controller port mode pc ram\n",
      "Topic 6: car engine dealer mile price model owner speed tire power\n",
      "Topic 7: thanks advance hi info anybody reply help information response question\n",
      "Topic 8: god jesus christian faith christ belief life religion word truth\n",
      "Topic 9: file directory format disk image ftp site utility help copy\n",
      "Topic 10: program image space code help graphic widget job source value\n",
      "Topic 11: problem error machine memory solution mouse duo apple screen line\n",
      "Topic 12: driver version printer mouse diamond bb mode site ftp color\n",
      "Topic 13: law gun government right state crime weapon israel country jew\n",
      "Topic 14: bank geb chastity skepticism intellect patient blood disease migraine weight\n",
      "Topic 15: game season baseball playoff espn night hockey wing tv fan\n",
      "Topic 16: software list price book sale address number offer phone computer\n",
      "Topic 17: bike motorcycle mile rider dod helmet road insurance advice course\n",
      "Topic 18: monitor color screen apple vga image display video mac vram\n",
      "Topic 19: time question thing day space group way article year answer\n"
     ]
    }
   ],
   "source": [
    "# print the topics with their most occuring words\n",
    "for topic_idx, topic in enumerate(nmf.components_):\n",
    "    top_words_idx = topic.argsort()[:-n_top_words-1:-1]\n",
    "    top_words = [vectorizer.get_feature_names_out()[i] for i in top_words_idx]\n",
    "    print(f\"Topic {topic_idx}:\", *top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b17febcc4130c68f2e7b85053bd8c8c27371546629f37a51ccc1ae40fbbf6be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
